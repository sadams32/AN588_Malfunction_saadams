---
title: "What‚Äôs Your Malfunction?"
format: html
editor: visual
theme: yeti
toc: true
toc-depth: 5
code-block-bg: true
code-block-border-left: "blue"
highlight-style: "gruvbox"
---

![](img/robot.png)

## Load Packages

```{r}
library(curl)
library(tidyverse)
library(gridExtra)
```

## Load Data

```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

## Task 1

### Instructions

*Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:*

:   Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default ‚Äútwo.sided‚Äù) and conf.level (default 0.95), to be used in the same way as in the function t.test().

:   When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=‚Äúless‚Äù or alternative=‚Äúgreater‚Äù, the same as in the use of x and y in the function t.test(). The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

:   The function should contain a check for the rules of thumb we have talked about (ùëõxùëù\> 5 and ùëõx (1‚àíùëù) \> 5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

:   The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

### Z.prop.test Function

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) {
  # require initial check for if distribution is normal w/ check.norm function
  check.norm <- function(p,n){
    if (n * p <= 5 && n * (1 - p) <= 5){
      warning("Your distribution may not be normal: np and n(1 - p) should both be > 5.")
    }
  }
  check.norm(p1, n1) # check conditions with check.norm function
  if(!is.null(p2) && !is.null(n2))
    check.norm(p2, n2)
  
  alpha <- 1 - conf.level # calculate alpha value
  crit <- qnorm(1 - alpha/2) # calculate critical values for CI
  
  # one-sample Z-test function
  if(is.null(p2) || is.null(n2)) {
    SE <- sqrt(p0 * (1 - p0) / n1) # calculate SE for Z test statistic
    Z <- (p1 - p0) / SE # calculate Z test statistic
    CI <- p1 + (c(-1, 1) * crit * SE) # p1 +/- the negative and positive values of crit * SE = confidence interval
    
    # calculate p-value
    if (alternative == "two.sided") {
      p_value <- 2 * pnorm(-abs(Z))
    } else if (alternative == "greater") {
      p_value <- 1 - pnorm(Z)
    } else {
      p_value <- pnorm(Z)
    }
  } 
  
  # two-sample Z-test function
  else {
    pstar <- (p1 * n1 + p2 * n2) / (n1 + n2) # pooled proportion
    SE <- sqrt((pstar * (1 - pstar)) * ((1/n1) + (1/n2)))
    Z <- (p1 - p2) / SE # critical values
    CI <- (p1 - p2) + (c(-1, 1) * crit * SE) # calculate confidence interval
    
    # calculate p-value
    if (alternative == "two.sided"){
      p_value <- 2 * pnorm(-abs(Z))
    } else if (alternative == "greater") {
      p_value <- 1 - pnorm(Z)
    } else {
      p_value <- pnorm(Z)
    }
  }
  return(list(Z = Z, P = p_value, CI = CI)) # return list of relevant values: Z (the test statistic), P (the appropriate p value), and CI (confidence interval)
}
```

//Challenge// not sure if else or elseif is more appropriate for the third statement for the alternative hypothesis - should I edit it to return a warning if the alternative is not any of the three?

### Examples

#### Example 1: One sample test

```{r}
Z.prop.test(p1 = 0.5, n1 = 100, p0 = 0.8)
```

#### Example 2: Two sample test

```{r}
Z.prop.test(p1 = 0.5, n1 = 100, p2 = 0.8, n2 = 35, p0 = 0.5)
```

#### Example 3: One sample test, violates check.norm

```{r}
Z.prop.test(p1 = 0.6, n1 = 5, p0 = 0.8)
```

## Task 2

*The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species‚Äô brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity\~brain size and log(longevity)\~log(brain size):*

:   Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

:   Identify and interpret the point estimate of the slope (ùõΩ1), as well as the outcome of the test associated with the hypotheses H0: ùõΩ1 = 0; HA: ùõΩ1 ‚â† 0. Also, find a 90 percent CI for the slope (ùõΩ1) parameter.

:   Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

:   Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

:   Looking at your two models, which do you think is better? Why?

### Linear Modeling

```{r}
# get rid of NA in dataset
d <- na.omit(d)

# Model 1: longevity~brain size
lm_model <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)

# Model 2: log(longevity)~log(brain size)
d <- d %>%
  mutate(log_longevity = log(MaxLongevity_m), log_brainsize = log(Brain_Size_Species_Mean))

log_lm_model <- lm(data = d, log_longevity ~ log_brainsize)

# summarize models
summary(lm_model)
summary(log_lm_model)
```

### Formulas for Plotting

```{r}
# Model 1
lm_intercept <- round(coef(lm_model)[1], 2) # intercept value in the lm_model result (index 1)
lm_slope <- round(coef(lm_model)[2], 2) # slope value in the lm_model result (index 2)
lm_formula <- paste("y = ", lm_slope, "x + ", lm_intercept) # format formula

lm_formula # view formula

# Model 2
log_lm_intercept <- round(coef(log_lm_model)[1], 2) # intercept value in the log_lm_model result (index 1)
log_lm_slope <- round(coef(log_lm_model)[2], 2) # slope value in the log_lm_model result (index 2)
log_lm_formula <- paste("y = ", log_lm_slope, "x + ", log_lm_intercept) # format formula

log_lm_formula # view formula
```

### Scatterplots

```{r}
# Model 1
lm_model_plot <- ggplot(d, aes(x = MaxLongevity_m, y = Brain_Size_Species_Mean)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x, color = "blue") + geom_text(aes(x = 450, y = 400, label = lm_formula), color = "red") + labs(title = "Longevity (mo.) vs. Brain Size (g)", x = "Longevity (months)", y = "Brain Size (grams)")

# Model 2
log_lm_model_plot <- ggplot(d, aes(x = log_longevity, y = log_brainsize)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x, color = "blue") + geom_text(aes(x = 6, y = 6, label = log_lm_formula), color = "red") + labs(title = "Log Model: Longevity (mo.) vs. Brain Size (g)", x = "log(Longevity (months))", y = "log(Brain Size (grams))")
```

```{r}
lm_model_plot
```

```{r}
log_lm_model_plot
```

### Identify and Interpret Point Estimate of the Slope (ùõΩ1) & Test Hypotheses

```{r}
# Model 1
lm_beta1 <- lm_slope
lm_ci <- confint(lm_model, level = 0.90)[2,]

lm_beta1
lm_ci

# Model 2
log_lm_beta1 <- log_lm_slope
log_lm_ci <- confint(log_lm_model, level = 0.90)[2,]

log_lm_beta1
log_lm_ci
```

Interpretation: reject the null hypothesis in favor of the alternative. That is, there is a significant linear relationship between brain size and longevity in both models (because beta1 does not equal 0 and the 0 is not contained in the confidence intervals for either model.)

### Compute CIs and Prediction Intervals for Plotting

#### Model 1

```{r}
# make new data frame (d1)
# sequence only to minimum and maximum values of all rows
d1 <- data.frame(Brain_Size_Species_Mean = seq(from = min(d$Brain_Size_Species_Mean), to = max(d$Brain_Size_Species_Mean), length.out = nrow(d)))

ci1 <- predict(lm_model, d1, interval = "confidence", level = 0.90) # predict confidence intervals

pi1 <- predict(lm_model, d1, interval = "prediction", level = 0.90) # prediction intervals

d1 <- cbind(d1, ci1, pi1) # add CIS and prediction intervals to new dataframe
names(d1) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") # name columns of new dataframe
head(d1)

# add new lines for CI and PI to plot for Model 1
lm_new <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
lm_new <- lm_new + geom_point(alpha = 1/2)
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIfit), colour = "black", lwd = 1)
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIlwr), colour = "blue")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIupr), colour = "blue")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = PIlwr), colour = "red")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = PIupr), colour = "red")

lm_new # view plot
```

#### Model 2

```{r}
# make new data frame (d2)
# sequence only to minimum and maximum values of all rows
d2 <- data.frame(log_brainsize = seq(from = min(d$log_brainsize), to = max(d$log_brainsize), length.out = nrow(d)))

ci2 <- predict(log_lm_model, d2, interval = "confidence", level = 0.90) # predict confidence intervals
pi2 <- predict(log_lm_model, d2, interval = "prediction", level = 0.90) # prediction intervals

d2 <- cbind(d2, ci2, pi2) # add CIS and prediction intervals to new dataframe

names(d2) <- c("log_brainsize", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") # name columns of new dataframe
head(d2)

# add new lines for CI and PI to plot for Model 2
log_lm_new <- ggplot(data = d, aes(x = log_brainsize, y = log_longevity))
log_lm_new <- log_lm_new + geom_point(alpha = 1/2)
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIfit), colour = "black", lwd = 1)
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIlwr), colour = "blue")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIupr), colour = "blue")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = PIlwr), colour = "red")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = PIupr), colour = "red")

log_lm_new # view plot
```

### Prediction Interval for Brain Size = 800 g

```{r}
# Model 1
species_test <- data.frame(Brain_Size_Species_Mean = 800)
predict(lm_model, species_test, interval = "prediction", level = 0.90)

# Model 2
species_test <- data.frame(log_brainsize = log(800))
predict(log_lm_model, species_test, interval = "prediction", level = 0.90)
```

I think that Model 2 (the log model) seems much more trustworthy for predicting a species with brain size = 800 grams. the upper and lower limits seem to be much more within the range of what is shown in the models and the log model with the CIs and PIs plotted appears to encapsulate the points more closely. So, Looking at these two models, I would think that my Model 2 is a better fit for the data.

## Notes

Final Push: March 16, 2025 5:44 pm
Push to add this note: March 27, 2025 8:09 pm 

### 1) What you learned from running their Original Homework Code that helped improve your own code.
I really liked that Sherry used a few cases to test her function for "Task 1." I ended up doing the same in my final assignment.

### 2) What you did in your own code that might help to improve theirs.
I suggested that they omit NA entries earlier in their code in case that messes with things later. Also, I think there might have been a mistake in using OR instead of AND in their function for task 1 for the conditions that needed to be checked. The way the data was called also wouldn't universally work on devices that are not Sherry's so I suggested she make an edit there.

### 3) What challenges, if any, you both faced in your code that could not be helped by comparison.
I think we both seemed to struggle a little writing the function and separating all the parts neatly, but got most of the important stuff in there in the end!

### 4) Whether the annotation/commenting on your peer‚Äôs Original Homework Code is readable and interpretable to you, and if not then how it could be improved.
I though Sherry's annotation/commenting was great! She included linked to the relevant modules which was a really nice detail. Also, she overall described her code really nicely
