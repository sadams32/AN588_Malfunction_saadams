---
title: "saadams_OriginalHomeworkCode_04"
format: html
editor: visual
theme: yeti
toc: true
toc-depth: 5
code-block-bg: true
code-block-border-left: "blue"
highlight-style: "gruvbox"
---

![](img/robot.png)

## Load Packages

```{r}
library(curl)
library(tidyverse)
library(gridExtra)
```

## Load Data

```{r}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

## Task 1

*Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:*

:   Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default ‚Äútwo.sided‚Äù) and conf.level (default 0.95), to be used in the same way as in the function t.test().

:   When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=‚Äúless‚Äù or alternative=‚Äúgreater‚Äù, the same as in the use of x and y in the function t.test(). The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

:   The function should contain a check for the rules of thumb we have talked about (ùëõxùëù\> 5 and ùëõx (1‚àíùëù) \> 5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

:   The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) {
  # require initial check for if distribution is normal w/ check.norm function
  check.norm <- function(p,n){
    if (n * p <= 5 && n * (1 - p) <= 5){
      warning("Your distribution may not be normal: np and n(1 - p) should both be > 5.")
    }
  }
  check.norm(p1, n1)
  if(!is.null(p2) && !is.null(n2))
    check.norm(p2, n2)
  
  alpha <- 1 - conf.level # calculate alpha value
  crit <- qnorm(1 - alpha/2) # calculate critical values for CI
  
  # one-sample Z-test function
  if(is.null(p2) || is.null(n2)) {
    SE <- sqrt(p0 * (1 - p0) / n1) # calculate SE for Z test statistic
    z <- (p1 - p0) / SE # calculate Z test statistic
    CI <- p1 + (c(-1, 1) * crit * SE) # p1 +/- the negative and positive values of crit * SE = confidence interval
    
    # calculate p-value
    if (alternative == "two.sided") {
      p_value <- 2 * pnorm(-abs(Z))
    } else if (alternative == "greater") {
      p_value <- 1 - pnorm(Z)
    } else {
      p_value <- pnorm(Z)
    }
  } 
  
  # two-sample Z-test function
  else {
    pstar <- (p1 + p2) / (n1 + n2) # pooled proportion
    SE <- sqrt((pstar * (1 - pstar)) * ((1/n1) + (1/n2)))
    z <- (p1 - p2) / SE # critical values
    CI <- (p1 - p2) + (c(-1, 1) * crit * SE) # calculate confidence interval
    
    # calculate p-value
    if (alternative == "two.sided"){
      p_value <- 2 * pnorm(-abs(Z))
    } else if (alternative == "greater") {
      p_value <- 1 - pnorm(Z)
    } else {
      p_value <- pnorm(Z)
    }
  }
  return(list(Z = z, P = p_value, CI = CI)) # return list of relevant values: Z (the test statistic), P (the appropriate p value), and CI (confidence interval)
}
```
//Challenge// not sure if else or elseif is more appropriate for the third statement for the alternative hypothesis - should I edit it to return a warning if the alternative is not any of the three?

## Task 2

*The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species‚Äô brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity\~brain size and log(longevity)\~log(brain size):*

:   Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

:   Identify and interpret the point estimate of the slope (ùõΩ1), as well as the outcome of the test associated with the hypotheses H0: ùõΩ1 = 0; HA: ùõΩ1 ‚â† 0. Also, find a 90 percent CI for the slope (ùõΩ1) parameter.

:   Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

:   Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

:   Looking at your two models, which do you think is better? Why?


### Linear Modeling
```{r}
# get rid of NA in dataset
d <- na.omit(d)

# Model 1: longevity~brain size
lm_model <- lm(data = d, MaxLongevity_m ~ Brain_Size_Species_Mean)

# Model 2: log(longevity)~log(brain size)
d <- d %>%
  mutate(log_longevity = log(MaxLongevity_m), log_brainsize = log(Brain_Size_Species_Mean))

log_lm_model <- lm(data = d, log_longevity ~ log_brainsize)

# summarize models
summary(lm_model)
summary(log_lm_model)
```



### Formulas for Plotting

```{r}
# Model 1
lm_intercept <- coef(lm_model)[1] # intercept value in the lm_model result (index 1)
lm_slope <- coef(lm_model)[2] # slope value in the lm_model result (index 2)
lm_formula <- paste("y = ", lm_slope, "x + ", lm_intercept) # format formula

lm_formula # view formula

# Model 2
log_lm_intercept <- coef(log_lm_model)[1] # intercept value in the log_lm_model result (index 1)
log_lm_slope <- coef(log_lm_model)[2] # slope value in the log_lm_model result (index 2)
log_lm_formula <- paste("y = ", log_lm_slope, "x + ", log_lm_intercept) # format formula

log_lm_formula #view formula
```

### Scatterplots
```{r}
# Model 1
lm_model_plot <- ggplot(d, aes(x = MaxLongevity_m, y = Brain_Size_Species_Mean)) + geom_point() + geom_smooth(method = "lm", se = FALSE, color = "blue") + geom_text(aes(x = 450, y = 400, label = lm_formula), color = "red") + labs(title = "Longevity (mo.) vs. Brain Size (g)", x = "Longevity (months)", y = "Brain Size (grams)")

# Model 2
log_lm_model_plot <- ggplot(d, aes(x = log_longevity, y = log_brainsize)) + geom_point() + geom_smooth(method = "lm", se = FALSE, color = "blue") + geom_text(aes(x = 6, y = 6, label = log_lm_formula), color = "red") + labs(title = "Log Model: Longevity (mo.) vs. Brain Size (g)", x = "log(Longevity (months))", y = "log(Brain Size (grams))")
```
//Challenge// My formulas are so long and the plot just doesn't look that nice to me - I don't really know if there is a better way to do this. I intially tried to write a function but got a little confused on how to change things to suit both models.

### Identify and Interpret Point Estimate of the Slope (ùõΩ1) & Test Hypotheses

```{r}
# Model 1
lm_beta1 <- lm_slope
lm_ci <- confint(lm_model, level = 0.90)["Brain_Size_Species_Mean",]

lm_beta1
lm_ci

# Model 2
log_lm_beta1 <- log_lm_slope
log_lm_ci <- confint(log_lm_model, level = 0.90)["log_brainsize",]

log_lm_beta1
log_lm_ci
```
//Challenge// I think I'm a little confused about the bracketing for this. I tried doing ex. [2,4] as before but it didn't work so I used the names in "" instead. I'm not sure why I had to do this here and not before. 

Interpretation: reject the null hypothesis in favor of the alternative. That is, there is a significant linear relationship between brain size and longevity in both models (because beta1 does not equal 0 and the 0 is not contained in the confidence intervals for either model.)

### Compute CIs and Prediction Intervals for Plotting

#### Model 1
```{r}
# make new data frame (d1)
# sequence only to minimum and maximum values of all rows
d1 <- data.frame(Brain_Size_Species_Mean = seq(from = min(d$Brain_Size_Species_Mean), to = max(d$Brain_Size_Species_Mean), length.out = nrow(d)))

ci1 <- predict(lm_model, d1, interval = "confidence", level = 0.90) # predict confidence intervals

pi1 <- predict(lm_model, d1, interval = "prediction", level = 0.90) # prediction intervals

d1 <- cbind(d1, ci1, pi1) # add CIS and prediction intervals to new dataframe
names(d1) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") # name columns of new dataframe
head(d1)

# add new lines for CI and PI to plot for Model 1
lm_new <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
lm_new <- lm_new + geom_point(alpha = 1/2)
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIfit), colour = "black", lwd = 1)
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIlwr), colour = "blue")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = CIupr), colour = "blue")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = PIlwr), colour = "red")
lm_new <- lm_new + geom_line(data = d1, aes(x = Brain_Size_Species_Mean, y = PIupr), colour = "red")

lm_new # view plot
```

#### Model 2
```{r}
# make new data frame (d2)
# sequence only to minimum and maximum values of all rows
d2 <- data.frame(log_brainsize = seq(from = min(d$log_brainsize), to = max(d$log_brainsize), length.out = nrow(d)))

ci2 <- predict(log_lm_model, d2, interval = "confidence", level = 0.90) # predict confidence intervals
pi2 <- predict(log_lm_model, d2, interval = "prediction", level = 0.90) # prediction intervals

d2 <- cbind(d2, ci2, pi2) # add CIS and prediction intervals to new dataframe

names(d2) <- c("log_brainsize", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr") # name columns of new dataframe
head(d2)

# add new lines for CI and PI to plot for Model 2
log_lm_new <- ggplot(data = d, aes(x = log_brainsize, y = log_longevity))
log_lm_new <- log_lm_new + geom_point(alpha = 1/2)
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIfit), colour = "black", lwd = 1)
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIlwr), colour = "blue")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = CIupr), colour = "blue")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = PIlwr), colour = "red")
log_lm_new <- log_lm_new + geom_line(data = d2, aes(x = log_brainsize, y = PIupr), colour = "red")

log_lm_new # view plot
```
//Challenge// I don't really know if this is the best way to add these lines to the plot/the neatest. I really just based this off the modules but I feel like there could be a better way to do this.

### Prediction Interval for Brain Size = 800 g
```{r}
# Model 1
species_test <- data.frame(Brain_Size_Species_Mean = 800)
predict(lm_model, species_test, interval = "prediction", level = 0.90)

# Model 2
species_test <- data.frame(log_brainsize = log(800))
predict(log_lm_model, species_test, interval = "prediction", level = 0.90)
```
I think that Model 2 (the log model) seems much more trustworthy for predicting a species with brain size = 800 grams. the upper and lower limits seem to be much more within the range of what is shown in the models and the log model with the CIs and PIs plotted appears to encapsulate the points more closely. So, Looking at these two models, I would think that my Model 2 is a better fit for the data.

//Challenge// I don't know if I should expand on my interpretation or if there is more to be said for how to look at the PIs and CIs.

